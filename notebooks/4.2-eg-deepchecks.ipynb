{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from deepchecks.vision.vision_data import BatchOutputFormat\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.transforms import CenterCrop\n",
    "from torch.utils.data import DataLoader\n",
    "from deepchecks.vision import VisionData\n",
    "from deepchecks.vision.suites import model_evaluation, train_test_validation, data_integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED = [\n",
    "    '../data/processed/datasets_processed/training_data/',\n",
    "    '../data/processed/datasets_processed/training_labels/',\n",
    "    '../data/processed/datasets_processed/testing_data/',\n",
    "    '../data/processed/datasets_processed/testing_labels/'\n",
    "]\n",
    "RATIO = 1\n",
    "MODEL_PATH = '/models/saved/10_50_0.1_0.25_unet_model.pth'\n",
    "BEST_MODEL = 'https://cdn.albertovalerio.com/datasets/crop_segmentation/models/my_unet_model.pth'\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = 'mps'\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'\n",
    "else:\n",
    "    DEVICE = 'cpu'\n",
    "LABEL_MAP = {0: 'no-weed', 1: 'weed'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko = '.DS_Store'\n",
    "train_i = os.listdir(PROCESSED[0])\n",
    "train_m = os.listdir(PROCESSED[1])\n",
    "test_i = os.listdir(PROCESSED[2])\n",
    "test_m = os.listdir(PROCESSED[3])\n",
    "if ko in train_i: train_i.remove(ko)\n",
    "if ko in train_m: train_m.remove(ko)\n",
    "if ko in test_i: test_i.remove(ko)\n",
    "if ko in test_m: test_m.remove(ko)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "\ttest_i,\n",
    "\ttest_m,\n",
    "\ttrain_size=.8,\n",
    "\ttest_size=.2,\n",
    "\trandom_state=3,\n",
    "\tshuffle=True\n",
    ")\n",
    "\n",
    "sampleT = int(len(X_train) * RATIO)\n",
    "sampleV = int(len(X_val) * RATIO)\n",
    "\n",
    "train_d = [[io.imread(PROCESSED[2]+v), io.imread(PROCESSED[3]+y_train[:sampleT][i])] for i, v in enumerate(X_train[:sampleT]) if io.imread(PROCESSED[2]+v).any()]\n",
    "test_d = [[io.imread(PROCESSED[2]+v), io.imread(PROCESSED[3]+y_val[:sampleV][i])] for i, v in enumerate(X_val[:sampleV]) if io.imread(PROCESSED[2]+v).any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "\ttransforms.ToPILImage(),\n",
    "\ttransforms.PILToTensor(),\n",
    "\ttransforms.ConvertImageDtype(torch.float)\n",
    "])\n",
    "train_dataset = [[transform(i[0]), transform(i[1])[0]] for i in train_d]\n",
    "test_dataset = [[transform(i[0]), transform(i[1])[0]] for i in test_d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 83\n",
      "Number of test images: 19\n",
      "Example output of an image shape: torch.Size([3, 360, 480])\n",
      "Example output of a label shape: torch.Size([360, 480])\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training images: {len(train_dataset)}')\n",
    "print(f'Number of test images: {len(test_dataset)}')\n",
    "print(f'Example output of an image shape: {train_dataset[0][0].shape}')\n",
    "print(f'Example output of a label shape: {train_dataset[0][1].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "\tdef __init__(self, inChannels, outChannels):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.conv1 = nn.Conv2d(inChannels, outChannels, 3)\n",
    "\t\tself.relu = nn.ReLU()\n",
    "\t\tself.conv2 = nn.Conv2d(outChannels, outChannels, 3)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.conv2(self.relu(self.conv1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\tdef __init__(self, channels=(3, 16, 32, 64)):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.encBlocks = nn.ModuleList(\n",
    "\t\t\t[Block(channels[i], channels[i + 1]) for i in range(len(channels) - 1)]\n",
    "\t\t)\n",
    "\t\tself.pool = nn.MaxPool2d(2)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tblockOutputs = []\n",
    "\t\tfor block in self.encBlocks:\n",
    "\t\t\tx = block(x)\n",
    "\t\t\tblockOutputs.append(x)\n",
    "\t\t\tx = self.pool(x)\n",
    "\t\treturn blockOutputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\tdef __init__(self, channels=(64, 32, 16)):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.channels = channels\n",
    "\t\tself.upconvs = nn.ModuleList(\n",
    "\t\t\t[nn.ConvTranspose2d(channels[i], channels[i + 1], 2, 2)\n",
    "\t\t\t\tfor i in range(len(channels) - 1)]\n",
    "\t\t)\n",
    "\t\tself.dec_blocks = nn.ModuleList(\n",
    "\t\t\t[Block(channels[i], channels[i + 1]) for i in range(len(channels) - 1)]\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x, encFeatures):\n",
    "\t\tfor i in range(len(self.channels) - 1):\n",
    "\t\t\tx = self.upconvs[i](x)\n",
    "\t\t\tencFeat = self.crop(encFeatures[i], x)\n",
    "\t\t\tx = torch.cat([x, encFeat], dim=1)\n",
    "\t\t\tx = self.dec_blocks[i](x)\n",
    "\t\treturn x\n",
    "\n",
    "\tdef crop(self, encFeatures, x):\n",
    "\t\t(_, _, H, W) = x.shape\n",
    "\t\tencFeatures = CenterCrop([H, W])(encFeatures)\n",
    "\t\treturn encFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "\tdef __init__(\n",
    "\t\tself, outSize, encChannels=(3, 16, 32, 64),\n",
    "\t\tdecChannels=(64, 32, 16), retainDim=True\n",
    "\t):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.encoder = Encoder(encChannels)\n",
    "\t\tself.decoder = Decoder(decChannels)\n",
    "\t\tself.head = nn.Conv2d(decChannels[-1], 1, 1)\n",
    "\t\tself.retainDim = retainDim\n",
    "\t\tself.outSize = outSize\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tencFeatures = self.encoder(x)\n",
    "\t\tdecFeatures = self.decoder(encFeatures[::-1][0], encFeatures[::-1][1:])\n",
    "\t\tmyMap = self.head(decFeatures)\n",
    "\t\tif self.retainDim:\n",
    "\t\t\tmyMap = F.interpolate(myMap, self.outSize)\n",
    "\t\treturn myMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('my_unet_model.pth'):\n",
    "    os.system('wget %s'%BEST_MODEL)\n",
    "model = torch.load('my_unet_model.pth', map_location=torch.device(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, input):\n",
    "\ttransform = transforms.Compose([\n",
    "\t\ttransforms.ToPILImage(),\n",
    "\t\ttransforms.PILToTensor(),\n",
    "\t\ttransforms.ConvertImageDtype(torch.float)\n",
    "\t])\n",
    "\tif isinstance(input, str):\n",
    "\t\timage = io.imread(input)\n",
    "\telse:\n",
    "\t\timage = input\n",
    "\timage = transform(image)\n",
    "\timage = image.unsqueeze(0)\n",
    "\tmodel.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\tpredMask = model(image.to(DEVICE)).squeeze()\n",
    "\t\tpredMask = torch.sigmoid(predMask)\n",
    "\t\tpredMask = predMask.cpu().numpy()\n",
    "\t\tpredMask = (predMask > .5) * 255\n",
    "\t\tpredMask = predMask.astype(np.uint8)\n",
    "\treturn predMask\n",
    "\n",
    "def convert_prediction(mask):\n",
    "\tx = mask.shape[0]\n",
    "\ty = mask.shape[1]\n",
    "\tmask_1 = np.zeros((x, y), dtype='float64')\n",
    "\tmask_2 = np.zeros((x, y), dtype='float64')\n",
    "\tfor i in range(x):\n",
    "\t\tfor j in range(y):\n",
    "\t\t\tif mask[i][j] == 0:\n",
    "\t\t\t\tmask_1[i][j] = 1.\n",
    "\t\t\tif mask[i][j] == 255:\n",
    "\t\t\t\tmask_2[i][j] = 1.\n",
    "\treturn nn.functional.softmax(torch.tensor(np.array([mask_1, mask_2])), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepchecks_collate_fn(batch) -> BatchOutputFormat:\n",
    "\n",
    "    # batch received as iterable of tuples of (image, label) and transformed to tuple of iterables of images and labels:\n",
    "    batch = tuple(zip(*batch))\n",
    "\n",
    "    # images:\n",
    "    images = [(tensor.numpy().transpose((1, 2, 0)) * 255).astype(np.uint8) for tensor in batch[0]]\n",
    "\n",
    "    #labels:\n",
    "    labels = [mask.type(torch.int8) for mask in batch[1]]\n",
    "\n",
    "    #predictions:\n",
    "    predictions = [make_predictions(model, img) for img in images]\n",
    "    predictions = [convert_prediction(pred) for pred in predictions]\n",
    "\n",
    "    return BatchOutputFormat(images=images, labels=labels, predictions=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, shuffle=True, collate_fn=deepchecks_collate_fn)\n",
    "test_loader = DataLoader(dataset=test_dataset, shuffle=True, collate_fn=deepchecks_collate_fn)\n",
    "\n",
    "training_data = VisionData(batch_loader=train_loader, task_type='semantic_segmentation', label_map=LABEL_MAP)\n",
    "test_data = VisionData(batch_loader=test_loader, task_type='semantic_segmentation', label_map=LABEL_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade2baa0eba94d8e9bcc0fad20ea05d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<div style=\"display:flex; flex-direction: column; gap: 10px;\">\\n                <di…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <label>\n",
       "                    Processing Batches:Train:<br/>\n",
       "                    <progress\n",
       "                        value='0'\n",
       "                        max='1'\n",
       "                        class='deepchecks'\n",
       "                    >\n",
       "                    </progress>\n",
       "                </label>\n",
       "                <span>0/1 [Time: 00:00]</span>\n",
       "            </div>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suite = model_evaluation()\n",
    "result = suite.run(training_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c920bc61e6f465f8828924b50006ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(HTML(value='\\n<h1 id=\"summary_XAJI0Y6DPBHSAHXTHV3A3ZMF8\">Model Evaluation S…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.0.0-report-deepchecks.html'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.save_as_html('4.2.1-report-deepchecks-model-evaluation.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf5bbe4f0fe4403b8e3973d9f8f8e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(HTML(value='\\n<h1 id=\"summary_XAJI0Y6DPBHSAHXTHV3A3ZMF8\">Train Test Validat…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suite = train_test_validation()\n",
    "result = suite.run(training_data, test_data)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.0.0-report-deepchecks-validation.html'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.save_as_html('4.1.1-report-deepchecks-validation.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Panun\\anaconda3\\lib\\site-packages\\deepchecks\\vision\\checks\\data_integrity\\abstract_property_outliers.py:107: UserWarning:\n",
      "\n",
      "Properties that have class_id as output_type will be skipped.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <label>\n",
       "                    Processing Batches:Train:<br/>\n",
       "                    <progress\n",
       "                        value='0'\n",
       "                        max='1'\n",
       "                        class='deepchecks'\n",
       "                    >\n",
       "                    </progress>\n",
       "                </label>\n",
       "                <span>0/1 [Time: 00:00]</span>\n",
       "            </div>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Panun\\anaconda3\\lib\\site-packages\\deepchecks\\vision\\checks\\data_integrity\\abstract_property_outliers.py:107: UserWarning:\n",
      "\n",
      "Properties that have class_id as output_type will be skipped.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003be9d96cd94539a6453245c5bd5042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(HTML(value='\\n<h1 id=\"summary_XAJI0Y6DPBHSAHXTHV3A3ZMF8\">Data Integrity Sui…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suite = data_integrity()\n",
    "result = suite.run(training_data, test_data)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.0.2-report-deepchecks-data-integrity.html'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.save_as_html('4.0.1-report-deepchecks-data-integrity.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
